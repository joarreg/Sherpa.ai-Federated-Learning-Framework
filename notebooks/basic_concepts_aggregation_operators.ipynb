{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning: Aggregation operators\n",
    "\n",
    "In this notebook we provide an explanation of the implementation of the different federated aggregation operators provided in the platform. Before discussing the different aggregation operators, we establish the federated configuration (for more information see [Basic Concepts Notebook](./basic_concepts.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import shfl\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "database = shfl.data_base.Emnist()\n",
    "train_data, train_labels, val_data, val_labels, test_data, test_labels = database.load_data()\n",
    "\n",
    "iid_distribution = shfl.data_distribution.IidDataDistribution(database)\n",
    "federated_data, test_data, test_labels = iid_distribution.get_federated_data(num_nodes=20, percent=10)\n",
    "\n",
    "def model_builder():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', strides=1, input_shape=(28, 28, 1)))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', strides=1))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.1))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return shfl.model.DeepLearningModel(model)\n",
    "\n",
    "\n",
    "class Reshape(shfl.private.FederatedTransformation):\n",
    "    \n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.data = np.reshape(labeled_data.data, (labeled_data.data.shape[0], labeled_data.data.shape[1], labeled_data.data.shape[2],1))\n",
    "        \n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, Reshape())\n",
    "\n",
    "class Normalize(shfl.private.FederatedTransformation):\n",
    "    \n",
    "    def __init__(self, mean, std):\n",
    "        self.__mean = mean\n",
    "        self.__std = std\n",
    "    \n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.data = (labeled_data.data - self.__mean)/self.__std\n",
    "        \n",
    "        \n",
    "mean = np.mean(train_data.data)\n",
    "std = np.std(train_data.data)\n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, Normalize(mean, std))\n",
    "\n",
    "test_data = np.reshape(test_data, (test_data.shape[0], test_data.shape[1], test_data.shape[2],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have loaded and federated the data and established the learning model, it only remains to establish the aggregation operator. At the moment, the following classes are included in the platform: `FedAvg` and `WeightedFedAvg`. The implementations of the federated aggregation operators are as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Averaging (`FedAvg`) Operator\n",
    "\n",
    "In this section, we detail the implementation of `FedAvg` (see [FedAVg](../shfl/federated_aggregator/avgfed_aggregator.py)) proposed  by Google in this [paper](https://arxiv.org/abs/1602.05629). \n",
    "\n",
    "It is based on the arithmetic mean of the local parameters $W_i$ trained in each of the local clients $C_i$. That is, the parameters $W$ of the global model after each round of training are\n",
    "\n",
    "$$W = \\frac{1}{n_{\\rm{C}}} \\sum_{i=1}^{n_{\\rm{C}}} W_i$$\n",
    "\n",
    "\n",
    "For its implementation, we create a class that implements [FederatedAggregator](../shfl/federated_aggregator/federated_aggregator.py) interface. The method `aggregate_weights` is overwritten calculating the mean of the local weights of each client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from shfl.federated_aggregator.federated_aggregator import FederatedAggregator\n",
    "\n",
    "\n",
    "class AvgFedAggregator(FederatedAggregator):\n",
    "    \"\"\"\n",
    "    Implementation of Average Federated Aggregator. It only uses a simple average of the parameters of all the models\n",
    "    \"\"\"\n",
    "\n",
    "    def aggregate_weights(self, clients_params):\n",
    "        clients_params_array = np.array(clients_params)\n",
    "\n",
    "        num_clients = clients_params_array.shape[0]\n",
    "        num_layers = clients_params_array.shape[1]\n",
    "        clients_params_array = clients_params_array.reshape(num_clients, num_layers)\n",
    "\n",
    "        aggregated_weights = np.array([np.mean(clients_params_array[:, layer], axis=0) for layer in range(num_layers)])\n",
    "\n",
    "        return aggregated_weights\n",
    "\n",
    "\n",
    "fedavg_aggregator = AvgFedAggregator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Federated Averaging (`WeightedFedAvg`) Operator\n",
    "\n",
    "In this section, we detail the implementation of `WeightedFedAvg` (see [WeightedFedAVg](../shfl/federated_aggregator/weighted_avgfed_aggregator.py)). It is the weighted version of `FedAvg`. The weight of each client $C_i$ is determined by the amount of client's data $n_i$ with respect to total training data $n$. That is, the parameters $W$ of the global model after each round of training are \n",
    "\n",
    "$$W =  \\sum_{i=1}^n \\frac{n_i}{n} W_i$$\n",
    "\n",
    "When all clients have the same amount of data it is equivalent to FedAvg.\n",
    "\n",
    "For its implementation, we create a class that implements `FederatedAggregator` interface. The method `aggregate_weights` is overwritten calculating the weighted mean of the local parameters of each client. For that purpose, we first ponderate the local parameters by the percentage and, after that, we sum the ponderated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from shfl.federated_aggregator.federated_aggregator import FederatedAggregator\n",
    "\n",
    "\n",
    "class WeightedAvgFedAggregator(FederatedAggregator):\n",
    "    \"\"\"\n",
    "    Implementation of Average Federated Aggregator. The aggregation of the parameters is based in the number of data \\\n",
    "    in every node.\n",
    "    \"\"\"\n",
    "\n",
    "    def aggregate_weights(self, clients_params):\n",
    "        clients_params_array = np.array(clients_params)\n",
    "\n",
    "        num_clients = clients_params_array.shape[0]\n",
    "        num_layers = clients_params_array.shape[1]\n",
    "        clients_params_array = clients_params_array.reshape(num_clients, num_layers)\n",
    "\n",
    "        ponderated_weights = np.array([self._percentage[client] * clients_params_array[client, :] for client in range(num_clients)])\n",
    "        aggregated_weights = np.array([np.sum(ponderated_weights[:, layer], axis=0) for layer in range(num_layers)])\n",
    "\n",
    "        return aggregated_weights\n",
    "    \n",
    "weighted_fedavg_aggregator = WeightedAvgFedAggregator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to establish de federated goverment with any of the implemented aggregation operators and start the federated learning process.\n",
    "The class `FederatedGovernment` manages the deployment of the model over the federated data, and is in charge of aggregating the parameters into a central node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_government = shfl.learning_approach.FederatedGovernment(model_builder, federated_data, fedavg_aggregator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_government.run_rounds(1, test_data, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sherpa_venvPy3",
   "language": "python",
   "name": "sherpa_venvpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
