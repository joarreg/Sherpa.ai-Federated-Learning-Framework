{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Methodology of Federated Learning\n",
    "\n",
    "In this notebook we study the different evaluation methodologies that we can use when we want to evaluate FL problems. First, we set up the FL configuration (for more information see [Basic Concepts Notebook](./basic_concepts.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import shfl\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "class Reshape(shfl.private.FederatedTransformation):\n",
    "    \n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.data = np.reshape(labeled_data.data, (labeled_data.data.shape[0], labeled_data.data.shape[1], labeled_data.data.shape[2],1))\n",
    "        \n",
    "class Normalize(shfl.private.FederatedTransformation):\n",
    "    \n",
    "    def __init__(self, mean, std):\n",
    "        self.__mean = mean\n",
    "        self.__std = std\n",
    "    \n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.data = (labeled_data.data - self.__mean)/self.__std\n",
    "        \n",
    "def model_builder():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', strides=1, input_shape=(28, 28, 1)))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', strides=1))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.1))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return shfl.model.DeepLearningModel(model)\n",
    "\n",
    "#Read data\n",
    "database = shfl.data_base.Emnist()\n",
    "train_data, train_labels, val_data, val_labels, test_data, test_labels = database.load_data()\n",
    "\n",
    "#Distribute among clients\n",
    "non_iid_distribution = shfl.data_distribution.NonIidDataDistribution(database)\n",
    "federated_data, test_data, test_labels = non_iid_distribution.get_federated_data(num_nodes=20, percent=10)\n",
    "\n",
    "#Set up aggregation operator\n",
    "aggregator = shfl.federated_aggregator.AvgFedAggregator()\n",
    "federated_government = shfl.learning_approach.FederatedGovernment(model_builder, federated_data, aggregator)\n",
    "\n",
    "#Reshape and normalize\n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, Reshape())\n",
    "\n",
    "mean = np.mean(test_data.data)\n",
    "std = np.std(test_data.data)\n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, Normalize(mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation methodology 1: global test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first evaluation methodology that we propose consists of the federated version of the classical evaluation methods. For that purpose, we use a common test dataset allocated in the server. We show the evaluation metrics (loss and accuracy in this case) in each round of learning both in local models and global updated model. We show the behaviour of this evaluation methodology as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy round 0\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2772a990>: [13.276649362182617, 0.17487500607967377]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2772a910>: [11.485916297531128, 0.28462499380111694]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2772aa90>: [12.950237517547608, 0.19642500579357147]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2772abd0>: [5.401505676078797, 0.6487749814987183]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2772ad10>: [11.450444860076905, 0.288875013589859]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a2772af50>: [7.8874158100128176, 0.5026999711990356]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a27739050>: [12.946188985443115, 0.19664999842643738]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a27739150>: [4.228973247241974, 0.7184249758720398]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a27739290>: [12.952880805206298, 0.19609999656677246]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a27739410>: [4.551164772558212, 0.7043250203132629]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a277394d0>: [6.614466170883179, 0.56597501039505]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a27739610>: [8.7480803565979, 0.45387500524520874]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a27739750>: [7.771764695930481, 0.5077250003814697]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a27739890>: [12.275676940917968, 0.23559999465942383]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a277399d0>: [12.941662697601318, 0.1969500035047531]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a27739b10>: [4.5537614236831665, 0.7067999839782715]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a27739c50>: [4.548600417900086, 0.7043499946594238]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a27739d90>: [8.126810558319091, 0.4898749887943268]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a27739ed0>: [11.804842121124267, 0.2659499943256378]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x1a27741050>: [7.753722988510132, 0.5121750235557556]\n",
      "Global model test performance : [6.94394196357727, 0.5251500010490417]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = np.reshape(test_data, (test_data.shape[0], test_data.shape[1], test_data.shape[2],1))\n",
    "federated_government.run_rounds(1, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This methodology is the simplest and shows both local and global models. The problem with this methodology is that the local evaluation metrics are biased by the distribution of test set data. That is, the performance of the local models is not properly represented when using a non-iid scenario (see [Federated Sampling](./federated_sampling.ipynb)) because the distribution of training data for each client is different from the data we test on. For that reason, we propose the following evaluation methodology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation methodology 2: global test dataset and local test datasets\n",
    "\n",
    "In this evaluation methodology we consider that there is, as in the previous one, a global test dataset and that each client has a local test dataset according to the distribution of their training data. Hence, in each round we show the evaluation metrics of each client on their local test and the global test. This evaluation methodology is more complete as it shows the performance of the local FL models in the global and local distribution of the data, which gives as more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
